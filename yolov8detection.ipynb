{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Seng-Pan/atomproject/blob/main/yolov8detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ErGbl8wq6ApB"
      },
      "outputs": [],
      "source": [
        "!pip install ultralytics kaggle roboflow pyyaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OgVEdjk33tBU"
      },
      "outputs": [],
      "source": [
        "!pip install opendatasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision"
      ],
      "metadata": {
        "id": "_y5mfox1-4K7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_S-kD1xb4Dbg",
        "outputId": "d4c53c61-3bd1-45d0-f9b7-e71e9f91e873"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username: seng285\n",
            "Your Kaggle Key: ··········\n",
            "Dataset URL: https://www.kaggle.com/datasets/prathumarikeri/american-sign-language-09az\n"
          ]
        }
      ],
      "source": [
        "import opendatasets as od\n",
        "od.download(\"https://www.kaggle.com/datasets/prathumarikeri/american-sign-language-09az\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "876pXNw_45Tn"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KWdyAjFd7CXW"
      },
      "outputs": [],
      "source": [
        "dataset_path = '/content/american-sign-language-09az/American'\n",
        "output_path = '/content/datasets/asl'\n",
        "os.makedirs(os.path.join(output_path, 'images/train'), exist_ok=True)\n",
        "os.makedirs(os.path.join(output_path, 'images/val'), exist_ok=True)\n",
        "os.makedirs(os.path.join(output_path, 'labels/train'), exist_ok=True)\n",
        "os.makedirs(os.path.join(output_path, 'labels/val'), exist_ok=True)\n",
        "# print(os.listdir(dataset_path))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data preprocessing"
      ],
      "metadata": {
        "id": "8B3t7XXn6kL-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QPq0CZ5S8ikg",
        "outputId": "62995d5a-8f54-4c47-fed6-dafad63eb438"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset processing complete!\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "import os\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image  # Import PIL for image resizing\n",
        "\n",
        "# hyperparameters\n",
        "target_size = (224, 224)\n",
        "batch_size = 8\n",
        "epochs = 10\n",
        "workers = 8               # workers for data loading\n",
        "validation_split = 0.15\n",
        "\n",
        "#Optimize CPU Performance\n",
        "os.environ[\"OMP_NUM_THREADS\"] = str(workers)\n",
        "os.environ[\"MKL_NUM_THREADS\"] = str(workers)\n",
        "os.environ[\"KMP_AFFINITY\"] = \"granularity=fine,compact,1,0\"\n",
        "os.environ[\"KMP_BLOCKTIME\"] = \"1\"\n",
        "\n",
        "# Create directories\n",
        "os.makedirs(os.path.join(output_path, 'images/train'), exist_ok=True)\n",
        "os.makedirs(os.path.join(output_path, 'images/val'), exist_ok=True)\n",
        "os.makedirs(os.path.join(output_path, 'labels/train'), exist_ok=True)\n",
        "os.makedirs(os.path.join(output_path, 'labels/val'), exist_ok=True)\n",
        "\n",
        "# Class mapping\n",
        "classes = sorted(os.listdir(dataset_path))\n",
        "class_to_id = {cls: idx for idx, cls in enumerate(classes)}\n",
        "\n",
        "for cls in classes:\n",
        "    cls_path = os.path.join(dataset_path, cls)\n",
        "    images = [img for img in os.listdir(cls_path) if os.path.isfile(os.path.join(cls_path, img))]\n",
        "\n",
        "    # Skip if no images are found\n",
        "    if not images:\n",
        "        print(f\"Skipping '{cls}' because no images were found.\")\n",
        "        continue\n",
        "\n",
        "    # Limit the number of images per class\n",
        "    if len(images) > 500:  # Further reduce dataset size\n",
        "        images = random.sample(images, 500)\n",
        "\n",
        "    # Split into training and validation sets\n",
        "    train_imgs, val_imgs = train_test_split(images, test_size=validation_split, random_state=42)\n",
        "\n",
        "    # Process training images\n",
        "    for img in train_imgs:\n",
        "        img_path = os.path.join(cls_path, img)\n",
        "        image = Image.open(img_path)\n",
        "        image = image.resize(target_size)  # Resize image\n",
        "        resized_img_path = os.path.join(output_path, 'images/train', img)\n",
        "        image.save(resized_img_path)\n",
        "        # Create label file\n",
        "        label_path = os.path.join(output_path, 'labels/train', os.path.splitext(img)[0] + '.txt')\n",
        "        with open(label_path, 'w') as f:\n",
        "            f.write(f'{class_to_id[cls]} 0.5 0.5 1.0 1.0')\n",
        "\n",
        "    # Process validation images\n",
        "    for img in val_imgs:\n",
        "        img_path = os.path.join(cls_path, img)\n",
        "        image = Image.open(img_path)\n",
        "        image = image.resize(target_size)  # Resize image\n",
        "        resized_img_path = os.path.join(output_path, 'images/val', img)\n",
        "        image.save(resized_img_path)\n",
        "        # Create label file\n",
        "        label_path = os.path.join(output_path, 'labels/val', os.path.splitext(img)[0] + '.txt')\n",
        "        with open(label_path, 'w') as f:\n",
        "            f.write(f'{class_to_id[cls]} 0.5 0.5 1.0 1.0')\n",
        "\n",
        "# Create dataset.yaml\n",
        "yaml_content = f\"\"\"\n",
        "path: {output_path}\n",
        "train: images/train\n",
        "val: images/val\n",
        "\n",
        "nc: {len(classes)}\n",
        "names: {classes}\n",
        "\"\"\"\n",
        "with open(os.path.join(output_path, 'asl.pt'), 'w') as f:\n",
        "    f.write(yaml_content)\n",
        "\n",
        "print(\"Dataset processing complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XCkbrJtUPD8Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4fb0715-7522-4347-d697-25ffc75ebdeb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------CPU Mode--------\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Check if GPU is available\n",
        "def check_gpu():\n",
        "    use_gpu = torch.cuda.is_available()\n",
        "    unit = \"cpu\"\n",
        "\n",
        "    if use_gpu:\n",
        "        print(\"-------GPU Mode--------\")\n",
        "        unit = \"cuda\"\n",
        "    else:\n",
        "        print(\"-------CPU Mode--------\")\n",
        "\n",
        "    device = torch.device(unit)\n",
        "    return device\n",
        "\n",
        "device = check_gpu()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### modeling"
      ],
      "metadata": {
        "id": "vvzRgBt66pdK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train yolov8 model\n",
        "\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Load the YOLOv8n model\n",
        "model = YOLO('yolov8n.pt')\n",
        "\n",
        "# Freeze initial layers to reduce computation\n",
        "for idx, param in enumerate(model.model.parameters()):\n",
        "    if idx < 100:  # Freeze first 100 layers\n",
        "        param.requires_grad = False\n",
        "\n",
        "# Custom training loop with validation frequency\n",
        "for epoch in range(epochs):\n",
        "    print(f\"Epoch {epoch + 1}/{epochs}\")\n",
        "\n",
        "    # Train for one epoch\n",
        "    model.train(\n",
        "        data=os.path.join(output_path, 'asl.pt'),\n",
        "        epochs=1,\n",
        "        imgsz=target_size[0],  # Match target_size\n",
        "        batch=batch_size,\n",
        "        name='asl_yolov8n_optimized',\n",
        "        device=device,\n",
        "        workers=workers,\n",
        "        augment=False,\n",
        "        single_cls=False,\n",
        "        lr0=0.01,       # inital learning rate  (fine-tune)\n",
        "        lrf=0.1,        # final lr  (f-t)\n",
        "        patience=5,     # f-t\n",
        "        weight_decay=0.0005  # Regularization   (f-t)\n",
        "    )\n",
        "\n",
        "    # Validate every 3 epochs\n",
        "    if (epoch + 1) % 3 == 0:\n",
        "        print(\"Running validation...\")\n",
        "        model.val()\n",
        "\n",
        "# Save model\n",
        "model.export(format='onnx')  # Export to ONNX format\n",
        "print(\"Model training and validation complete!\")"
      ],
      "metadata": {
        "id": "ZVLGd5iRBetB"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMGCcVW/iS7w+kwD9A8kRM0",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}